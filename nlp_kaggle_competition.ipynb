{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bee59fa1-366b-4895-8fca-76d6e6af4fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "import nltk\n",
    "import string\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "import numpy as np \n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1b283d-edc8-45f8-aaaf-2ccf388304eb",
   "metadata": {},
   "source": [
    "# Loading data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a132300-ff32-4bbb-a5d2-c2579cdc6f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4dceb65b-6ff9-4a88-89a7-71a33f51b34f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = train_df.copy()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "916aedd5-7edd-4f54-881e-423cedb56055",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7613 entries, 0 to 7612\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   id      7613 non-null   int64 \n",
      " 1   text    7613 non-null   object\n",
      " 2   target  7613 non-null   int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 178.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9deec1f4-e59d-440c-b39a-e5136d8803f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resulting dataframe shape\n",
      "columns : Index(['id', 'text', 'target'], dtype='object')\n",
      "shape: (7613, 3)\n"
     ]
    }
   ],
   "source": [
    "df = df.drop(['keyword', 'location'], axis=1)\n",
    "print(\"resulting dataframe shape\")\n",
    "print(\"columns :\", df.columns)\n",
    "print(\"shape:\", df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49c71875-24b8-4ec8-b896-f5ebed14872d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id        0\n",
       "text      0\n",
       "target    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking for null values \n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b410b433-163c-47e4-b34b-3b6b786df183",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking for duplicated values \n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91f3c23c-7f54-4070-8a4c-ed3f670352ee",
   "metadata": {},
   "source": [
    "# preprocessing function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "68631d40-87b2-45df-b2a9-aef5ba67b76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_tweet(tweet):\n",
    "    \"\"\" Process Tweet function\n",
    "    input: \n",
    "        tweet : a string containig a tweet\n",
    "    ouput:\n",
    "        tweet_clean : list containig words of processed tweet\n",
    "    \"\"\"\n",
    "    stemmer = PorterStemmer()\n",
    "    stop_words = stopwords.words('english')\n",
    "    # remove stock market tickers like $GE\n",
    "    tweet = re.sub(r'\\$\\w*', '', tweet)\n",
    "    # remove old style retweet text \"RT\"\n",
    "    tweet = re.sub(r'^RT[\\s]+', '', tweet)\n",
    "    # remove hyperlinks    \n",
    "    tweet = re.sub(r'https?://[^\\s\\n\\r]+', '', tweet)\n",
    "    # remove hashtags\n",
    "    tweet = re.sub(r'#', '', tweet)\n",
    "    # tokenize tweets\n",
    "    tokenizer = TweetTokenizer(preserve_case=False, reduce_len=True,\n",
    "                              strip_handles=True)\n",
    "    # converting sentence to tokens\n",
    "    tokens = tokenizer.tokenize(tweet)\n",
    "    tweet_clean = []\n",
    "    for word in tokens:\n",
    "        if word not in stop_words and word not in string.punctuation:\n",
    "            tweet_clean.append(stemmer.stem(word))\n",
    "    return tweet_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad476f3-cd9c-4eed-b9dd-96424db251aa",
   "metadata": {},
   "source": [
    "# Feature Extraction function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd57735e-0e72-47a1-a247-fcc835c13165",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_freqs(tweet, ys):\n",
    "    \"\"\" Build Freqs Function \n",
    "    Input:\n",
    "        tweet: a string containing a tweet\n",
    "        ys: m x 1 array containig target label for each tweet\n",
    "            (either 0 or 1)\n",
    "    output:\n",
    "        freqs: a dictionary mapping each (word, lable) pair with frequency \n",
    "    \"\"\"\n",
    "    yslist = np.squeeze(ys).tolist()\n",
    "    freqs = {}\n",
    "    for y, tweet in zip(ys, tweet):\n",
    "        for word in process_tweet(tweet):\n",
    "            pair = (word, y)\n",
    "            if pair in freqs:\n",
    "                freqs[pair] += 1\n",
    "            else:\n",
    "                freqs[pair] = 1\n",
    "    return freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d48af983-b228-4f86-91e2-cd79f63816a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = df['text'].tolist()\n",
    "train_y = df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df7ad0fc-2c9a-4b6f-87f5-5f25004b7c00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7613,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f0254bc3-d0bc-40bb-bdbd-0df67bc8503f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15911"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freqs = build_freqs(train_x, train_y)\n",
    "len(freqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9e70c6a6-1f6f-4732-b780-9eb1c9e21cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    \"\"\" Sigmoid function \n",
    "    Input: \n",
    "        z: input(array or scaler)\n",
    "    outupt:\n",
    "        h: sigmoid of z\n",
    "    \"\"\"\n",
    "    h = 1 / (1 + np.exp(-z))\n",
    "    return h "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "92bd5523-1c54-4713-849f-5ecd91fc93c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradientDescent(x, y, theta, alpha, num_iter):\n",
    "    \"\"\" Gradient Descent function \n",
    "    Input:\n",
    "        x: input array of shape (m, n+1)\n",
    "        y: target lable of matrix x,\n",
    "        theta: weight vector of dimension (n+1, 1)\n",
    "        alpha: learning rate\n",
    "        num_iter: number of iterations of model training\n",
    "    Ouput:\n",
    "        J: final cost\n",
    "        theta: final weights after last iteration completion \n",
    "    \"\"\"\n",
    "    m = len(x)\n",
    "    for i in range(0, num_iter):\n",
    "\n",
    "        # get z, the dot product of x and theta\n",
    "        z = np.dot(x, theta)\n",
    "        \n",
    "        # get sigmoid of z\n",
    "        h = sigmoid(z)\n",
    "        \n",
    "        # compute cost \n",
    "        J = (-1/m)*np.sum(y * np.log(h) + (1-y) * np.log(1-h))\n",
    "\n",
    "        # update the weights\n",
    "        theta = theta - alpha* np.dot(x.T, (h - y)) / m\n",
    "\n",
    "    J = float(J)\n",
    "    return J, theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c03905ea-2a8a-4830-92d8-37863237dffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cost after training is 0.67094970.\n",
      "The resulting vector of weights is [np.float64(4.1e-07), np.float64(0.00035658), np.float64(7.309e-05)]\n"
     ]
    }
   ],
   "source": [
    "# Check the function\n",
    "# Construct a synthetic test case using numpy PRNG functions\n",
    "np.random.seed(1)\n",
    "# X input is 10 x 3 with ones for the bias terms\n",
    "tmp_X = np.append(np.ones((10, 1)), np.random.rand(10, 2) * 2000, axis=1)\n",
    "# Y Labels are 10 x 1\n",
    "tmp_Y = (np.random.rand(10, 1) > 0.35).astype(float)\n",
    "\n",
    "# Apply gradient descent\n",
    "tmp_J, tmp_theta = gradientDescent(tmp_X, tmp_Y, np.zeros((3, 1)), 1e-8, 700)\n",
    "print(f\"The cost after training is {tmp_J:.8f}.\")\n",
    "print(f\"The resulting vector of weights is {[round(t, 8) for t in np.squeeze(tmp_theta)]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "7851ab6f-c701-4166-b787-285bd53710f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(tweet, freqs, process_tweet=process_tweet):\n",
    "    \"\"\" Extract Featues function \n",
    "    Input: \n",
    "        tweet: string containing a tweet\n",
    "        freqs: a dictionary mapping each (word, label) pair with frequency \n",
    "    Output:\n",
    "        x: a feature vector of dimension(1, 3)\n",
    "    \"\"\"\n",
    "    # process_tweet\n",
    "    word_l = process_tweet(tweet)\n",
    "    # 3 elements [bias, postitive, negative ] \n",
    "    x = np.zeros(3)\n",
    "\n",
    "    #bias term is set to 1\n",
    "    x[0] = 1\n",
    "\n",
    "    # loop through each word in the list\n",
    "    for word in word_l:\n",
    "\n",
    "        #increment the word count for the label=1\n",
    "        x[1] += freqs.get((word, 1), 0)\n",
    "\n",
    "        # do the same for label=0\n",
    "        x[2] += freqs.get((word, 0), 0)\n",
    "    x = x[None, :]\n",
    "    assert(x.shape == (1,3))\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "85a924eb-5196-4a05-9a46-606619f72de3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  1. 162. 148.]]\n"
     ]
    }
   ],
   "source": [
    "# Checking function\n",
    "# test 1\n",
    "# test on training data\n",
    "tmp1 = extract_features(train_x[0], freqs)\n",
    "print(tmp1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f48d8c06-9d72-458b-b615-0de0d5f5f732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "# test 2:\n",
    "# check for when the words are not in the freqs dictionary\n",
    "tmp2 = extract_features('blorb bleeeeb bloooob', freqs)\n",
    "print(tmp2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8ea39a-16ab-4ac6-807a-4c042c5d61b6",
   "metadata": {},
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c9feb23d-180c-486d-b6e5-5735dadd88ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7613,)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "1732687e-fea6-4578-89e7-d2e71e19aaad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cost after training is 0.51663997.\n",
      "The resulting vector of weights is [np.float64(-0.11642076), np.float64(0.00809115), np.float64(-0.00849864)]\n"
     ]
    }
   ],
   "source": [
    "# collect the features 'x' and stack them into a matrix 'X'\n",
    "X = np.zeros((len(train_x), 3))\n",
    "for i in range(len(train_x)):\n",
    "    X[i, :]= extract_features(train_x[i], freqs)\n",
    "\n",
    "# training labels corresponding to X\n",
    "Y = np.array(train_y)\n",
    "Y = Y.reshape((len(train_y), 1))\n",
    "\n",
    "# Apply gradient descent\n",
    "J, theta = gradientDescent(X, Y, np.zeros((3, 1)), 1e-5, 500000)\n",
    "print(f\"The cost after training is {J:.8f}.\")\n",
    "print(f\"The resulting vector of weights is {[round(t, 8) for t in np.squeeze(theta)]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "03809ccd-ad1d-4f42-b420-745c953dc137",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_tweet(tweet, freqs, theta):\n",
    "    \"\"\" Predict Tweet function\n",
    "    Input: \n",
    "        tweet: a string containing a tweet\n",
    "        freqs: a dictionary mapping (word, label) with frequency\n",
    "        theta: weights (3,1)\n",
    "    Output:\n",
    "        y_pred: probability value of a tweet being label=1 or lable=0\n",
    "    \"\"\"\n",
    "    x = extract_features(tweet, freqs)\n",
    "\n",
    "    # make prediction \n",
    "    y_pred = 1 / (1 + np.exp(- np.dot(x, theta)))\n",
    "    \n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "8ed8637f-5691-48d9-8531-0c7b727d741b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.96507246]])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_tweet = train_x[500]\n",
    "predict_tweet(my_tweet, freqs, theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "cd03786d-3444-49ac-9770-f353cc8ac060",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(1)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y[500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "1a958013-5336-4421-a2dc-0dc86f30c982",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_tweet = test_df['text'].tolist()\n",
    "\n",
    "y_hats = []\n",
    "for tweet in test_tweet:\n",
    "    # get the prediction \n",
    "    y_pred = predict_tweet(tweet, freqs, theta)\n",
    "\n",
    "    if y_pred > 0.5:\n",
    "        # append 1.0 \n",
    "        y_hats.append(1)\n",
    "    else:\n",
    "        # append 0.0\n",
    "        y_hats.append(0)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "849df78d-b421-4a94-bb92-4dd668222f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df = pd.DataFrame({\"id\": test_df[\"id\"], \n",
    "                             \"target\": y_hats})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "fe865e06-f3dd-41b2-9627-c6af9ba7c6f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df.to_csv('log_reg.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4369861-1235-46b3-8cde-fbe6af01eed0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
